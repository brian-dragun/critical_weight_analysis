# ESA Baseline Testing - Executive Summary

Generated: 2025-08-29 17:47:41 UTC

## Overview

This report summarizes the baseline performance metrics for the Extreme Sensitivity Analysis (ESA) research project. The baseline establishes ground truth performance across our model suite before weight perturbation experiments.

## Model Performance Summary

| Model | Parameters | Perplexity | Token Accuracy | Throughput (tok/s) | VRAM (GB) |
|-------|------------|------------|----------------|-------------------|-----------|
| Llama-3.1-8B | 8B | 1.03 | 99.4% | 24277 | 16.9 |
| Phi-3-mini-4k-instruct | 3.8B | 1.03 | 99.3% | 28337 | 7.6 |
| Mistral-7B-v0.3 | 7B | 1.03 | 99.3% | 25533 | 14.0 |
| Phi-3-mini-4k-instruct | 3.8B | 1.11 | 97.3% | 5451 | 7.3 |
| Llama-3.1-8B | 8B | 1.11 | 97.6% | 5791 | 15.5 |
| Mistral-7B-v0.3 | 7B | 1.14 | 97.3% | 5187 | 13.7 |
| pythia-1.4b | 1.4B | 1.20 | 96.9% | 8507 | 2.9 |

## Key Insights

### Performance Leaders
- **Best Perplexity**: Llama-3.1-8B (1.03)
- **Best Accuracy**: Llama-3.1-8B (99.4%)
- **Best Throughput**: Phi-3-mini-4k-instruct (28337 tok/s)

### Model Analysis
- **Average Perplexity**: 1.09
- **Perplexity Range**: 1.03 - 1.20

## Testing Configuration

- **Evaluation Method**: Automated baseline testing via baseline_runner.py
- **Precision**: bfloat16 (bf16) for optimal memory efficiency
- **Batch Strategy**: Dynamic micro-batching based on context length
- **Device Mapping**: Automatic GPU allocation
- **Reproducibility**: Fixed random seeds for consistent results

## Statistical Reliability

All metrics computed using:
- CrossEntropyLoss with ignore_index=-100 for padding
- Token-level accuracy excluding padding tokens
- Perplexity via exp(loss) transformation
- CUDA memory tracking for peak VRAM usage
- Wall-clock time measurement for throughput calculation

## Next Steps

1. **Standard Baselines**: Run `make standard-core` for comprehensive multi-dataset evaluation
2. **Extended Analysis**: Execute `make extended-llama` for long-context and zero-shot testing
3. **Weight Perturbation**: Begin ESA sensitivity experiments using these baseline metrics
4. **Scaling Studies**: Validate performance patterns across model size spectrum

## Research Implications

The baseline results establish critical ground truth metrics for ESA research:
- Performance benchmarks for detecting sensitivity-induced degradation
- Computational efficiency baselines for perturbation experiment planning
- Model selection validation for targeted sensitivity analysis
- Statistical foundations for significance testing in weight perturbation studies

Baseline stability across models provides robust foundation for systematic weight sensitivity analysis in subsequent ESA experiments.
